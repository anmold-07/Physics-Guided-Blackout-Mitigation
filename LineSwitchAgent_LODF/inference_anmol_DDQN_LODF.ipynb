{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import grid2op\n",
    "import numpy as np\n",
    "from lightsim2grid import LightSimBackend          # highly recommended!\n",
    "from MyRewards import RLReward, MarginReward, RedisActionCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_numbers = {} # \"31500_\"\n",
    "\n",
    "# Create a list of strings with increments of 1000 or 500, excluding the ones in the set\n",
    "number_list = []\n",
    "\n",
    "start, end = 35000, 67000\n",
    "\n",
    "for number in range(start, end + 1):\n",
    "    increment = 1000 if number <= 29000 else 1000\n",
    "    if number % increment == 0:\n",
    "        number_str = str(number) + \"_\"\n",
    "        if number_str not in excluded_numbers:\n",
    "            number_list.append(number_str)\n",
    "\n",
    "print(number_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "for string_number in number_list:\n",
    "    \n",
    "    NB_EPISODE = 32\n",
    "    # choose the desired model\n",
    "    lambdaa = 0.0\n",
    "    line_switch_cost = 1.5\n",
    "\n",
    "    model = string_number\n",
    "    signature = \"36bus_posttrain-model_anmol_LODF-try12\" + \"_\" + str(line_switch_cost) + \"_\" + str(lambdaa)\n",
    "    inference_process = \"inf1_\"\n",
    "    fileame = \"saved_models\" + \"_\" + str(line_switch_cost) + \"_\" + str(lambdaa) + \".txt\"\n",
    "    \n",
    "    if inference_process==\"inf1_\":\n",
    "        from agent_exp import MyAgent\n",
    "    else:\n",
    "        from agent_exp2 import MyAgent\n",
    "\n",
    "    def make_agent(env, submission_dir):\n",
    "        \"\"\"\n",
    "        This function will be used by codalab to create your agent. It should accept exactly an environment and a path\n",
    "        to your submission directory and return a valid agent.\n",
    "        \"\"\"\n",
    "\n",
    "        def powerFlowLimitsFunction(env):\n",
    "            \"\"\"\n",
    "            Power Flow Limits array (necessary, needed only once at the start) \n",
    "            Size: number of branches in the \"initial/starting\" grid.\n",
    "            power-flow limits on each line in the \"INITIAL\" power-grid. Go to array to extract the power-line limit.\n",
    "            after my thorough research, power flow limits on each grid2op branch (transmission line and transformer) can be found as:\n",
    "            \"\"\"\n",
    "            baseVoltagesForEachLine = np.array([138]*45 + [345]*3 + [138]*7 + [345]*4)         # manually building it since the base voltages can be recognized from the previous section.\n",
    "            powerFlowLimits = np.abs(env.get_thermal_limit())*baseVoltagesForEachLine*1000*np.sqrt(3)\n",
    "            powerFlowLimits = powerFlowLimits/1e6                          # power flow limits in MWs\n",
    "            return powerFlowLimits\n",
    "\n",
    "        powerFlowLimits = powerFlowLimitsFunction(env) # will not change with time steps\n",
    "        init_obs = env.reset()\n",
    "\n",
    "        agent = MyAgent(env.observation_space, env.action_space, env._init_grid_path, init_obs, powerFlowLimits)\n",
    "        import os\n",
    "        agent.load(os.path.join(submission_dir, model + signature, \"DDDQN_random_train.h5\"))\n",
    "        return agent\n",
    "\n",
    "    # reward must be a subclass of grid2op.Reward.BaseReward.BaseReward:\n",
    "    selected_reward_function = RLReward(lambdaa, line_switch_cost)\n",
    "    other_rewards = { \"margin_reward\": MarginReward, \"action_cost\": RedisActionCost }\n",
    "\n",
    "\n",
    "    env_name = \"l2rpn_neurips_2020_track1_small_test_random_32\"\n",
    "    #\"l2rpn_neurips_2020_track1_small_December\" # \"l2rpn_neurips_2020_track1_small_test_random_28\"\n",
    "\n",
    "    env = grid2op.make(env_name,\n",
    "                       reward_class=selected_reward_function,\n",
    "                       #param=custom_params,\n",
    "                       other_rewards = other_rewards,\n",
    "                       backend=LightSimBackend(),\n",
    "                       opponent_init_budget=0, opponent_budget_per_ts=0\n",
    "                       )\n",
    "\n",
    "\n",
    "    agent = make_agent(env, \"C:\\\\Users\\\\dwivea2\\\\Desktop\\\\RL code\\\\CustomAgent _LODF\")\n",
    "\n",
    "\n",
    "    from grid2op.Runner import Runner\n",
    "    from tqdm.notebook import tqdm\n",
    "    runner = Runner(**env.get_params_for_runner(), agentClass=None, agentInstance=agent)\n",
    "\n",
    "\n",
    "    PATH_SAVE = inference_process + model + \"36bus_saved_experiment_anmol\" + \"_\" + str(line_switch_cost) + \"_\" + str(lambdaa)\n",
    "    res = runner.run(nb_episode=NB_EPISODE, path_save=PATH_SAVE, env_seeds=list(range(NB_EPISODE)))\n",
    "\n",
    "    avgSurvTime = []\n",
    "    avgCumRewad = []\n",
    "\n",
    "    for chron_name, _, cum_reward, nb_time_step, max_ts in res:\n",
    "        avgSurvTime.append(nb_time_step)\n",
    "        avgCumRewad.append(cum_reward)\n",
    "\n",
    "    #msg_tmp = \"\\tFor chronics located at {}\\n\".format(chron_name)\n",
    "    #msg_tmp += \"\\t\\t - cumulative reward: {:.2f}\\n\".format(cum_reward)\n",
    "    #msg_tmp += \"\\t\\t - number of time steps completed: {:.0f} / {:.0f}\\n\".format(nb_time_step, max_ts)\n",
    "\n",
    "    \n",
    "    with open(fileame, \"a\") as result_file:\n",
    "        result_file.write(f\"Model: {string_number}\\n\")\n",
    "        \n",
    "        result_file.write(\"Average Survival Time:\\n\")\n",
    "        result_file.write(\", \".join(map(str, avgSurvTime)) + \"\\n\")\n",
    "\n",
    "    avg_survival_time = np.average(avgSurvTime)\n",
    "    max_timestep = env.chronics_handler.max_timestep()\n",
    "    avg_cumulative_reward = np.average(avgCumRewad)\n",
    "\n",
    "    # Append the averages to the result file\n",
    "    with open(fileame, \"a\") as result_file:\n",
    "        result_file.write(f\"Average Survival Time: {avg_survival_time} / {max_timestep} time steps.\\n\")\n",
    "        result_file.write(f\"Average Cumulative Reward is: {avg_cumulative_reward}\\n\")\n",
    "        result_file.write(\"\\n\")\n",
    "\n",
    "    print(avgSurvTime)\n",
    "    print(\"Average Survival Time:\", avg_survival_time, \"/\", max_timestep, \"time steps.\")\n",
    "    print(\"Average Cumulative Reward is:\", avg_cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b6660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
